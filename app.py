# FastAPI Orchestrator for AI Agent MVP
# Complete implementation with sequential prompt execution and file management

import os
import re
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

from openrouter_service import get_gemini_response

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="AI Agent MVP", 
    version="1.0.0",
    description="Self-Improving AI Agent for Automatic Software Development"
)

class ProjectRequest(BaseModel):
    """Request model for project generation"""
    description: str
    
class ProjectResponse(BaseModel):
    """Response model for project generation"""
    success: bool
    message: str
    execution_time: float
    outputs: Dict[str, str]

class AIAgentOrchestrator:
    """
    Main orchestrator class that manages the sequential execution of AI prompts
    and handles file operations for the generated content
    """
    
    def __init__(self):
        """Initialize orchestrator with paths and templates"""
        self.prompts_dir = "prompts"
        self.outputs_dir = "outputs"
        self.source_code_dir = os.path.join(self.outputs_dir, "source_code")
        
        # Ensure output directories exist
        os.makedirs(self.outputs_dir, exist_ok=True)
        os.makedirs(self.source_code_dir, exist_ok=True)
        
        logger.info("AI Agent Orchestrator initialized successfully")

    def load_prompt_template(self, prompt_name: str) -> str:
        """
        Load prompt template from prompts directory
        
        Args:
            prompt_name (str): Name of the prompt file (without .txt extension)
            
        Returns:
            str: Prompt template content
        """
        try:
            prompt_path = os.path.join(self.prompts_dir, f"{prompt_name}.txt")
            with open(prompt_path, 'r', encoding='utf-8') as file:
                return file.read()
        except FileNotFoundError:
            logger.error(f"‚ùå Prompt template not found: {prompt_name}.txt")
            raise HTTPException(status_code=500, detail=f"Prompt template {prompt_name} not found")
        except Exception as e:
            logger.error(f"‚ùå Error loading prompt template {prompt_name}: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Error loading prompt: {str(e)}")

    def save_output(self, filename: str, content: str, subdirectory: str = None) -> str:
        """
        Save generated content to output file
        
        Args:
            filename (str): Name of the output file
            content (str): Content to save
            subdirectory (str): Optional subdirectory within outputs
            
        Returns:
            str: Path of the saved file
        """
        try:
            if subdirectory:
                output_path = os.path.join(self.outputs_dir, subdirectory, filename)
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
            else:
                output_path = os.path.join(self.outputs_dir, filename)
            
            # Add metadata header
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            header = f"# Generated by AI Agent MVP\n# Timestamp: {timestamp}\n# File: {filename}\n\n"
            
            with open(output_path, 'w', encoding='utf-8') as file:
                file.write(header + content)
            
            logger.info(f"‚úÖ Output saved: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Error saving output {filename}: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Error saving output: {str(e)}")

    async def execute_analysis_phase(self, project_description: str) -> str:
        """
        Phase 1: Project Analysis
        
        Args:
            project_description (str): User's project description
            
        Returns:
            str: Generated analysis content
        """
        logger.info("üîç Starting Phase 1: Project Analysis")
        
        # Load and prepare prompt
        analysis_prompt = self.load_prompt_template("analysis")
        formatted_prompt = analysis_prompt.replace("{project_description}", project_description)
        
        # Get Gemini 2.5 Pro response via OpenRouter
        analysis_content = get_gemini_response(formatted_prompt)
        if not analysis_content:
            raise HTTPException(status_code=500, detail="Failed to generate project analysis")
        
        # Save output
        self.save_output("analysis.md", analysis_content)
        
        logger.info("‚úÖ Phase 1 completed: Project Analysis")
        return analysis_content

    async def execute_design_phase(self, analysis_content: str) -> str:
        """
        Phase 2: Software Architecture Design
        
        Args:
            analysis_content (str): Content from analysis phase
            
        Returns:
            str: Generated design content
        """
        logger.info("üèóÔ∏è Starting Phase 2: Software Architecture Design")
        
        # Load and prepare prompt
        design_prompt = self.load_prompt_template("design")
        formatted_prompt = design_prompt.replace("{analysis_content}", analysis_content)
        
        # Get Gemini 2.5 Pro response via OpenRouter
        design_content = get_gemini_response(formatted_prompt)
        if not design_content:
            raise HTTPException(status_code=500, detail="Failed to generate software design")
        
        # Save output
        self.save_output("design.md", design_content)
        
        logger.info("‚úÖ Phase 2 completed: Software Architecture Design")
        return design_content

    async def execute_coding_phase(self, design_content: str) -> str:
        """
        Phase 3: Code Implementation
        
        Args:
            design_content (str): Content from design phase
            
        Returns:
            str: Generated source code content
        """
        logger.info("üíª Starting Phase 3: Code Implementation")
        
        # Load and prepare prompt
        coding_prompt = self.load_prompt_template("coding")
        formatted_prompt = coding_prompt.replace("{design_content}", design_content)
        
        # Get Gemini 2.5 Pro response via OpenRouter
        source_code_content = get_gemini_response(formatted_prompt)
        if not source_code_content:
            raise HTTPException(status_code=500, detail="Failed to generate source code")
        
        # Save output (source code goes to source_code directory)
        self.save_output("implementation.md", source_code_content, "source_code")
        
        logger.info("‚úÖ Phase 3 completed: Code Implementation")
        return source_code_content

    async def execute_testing_phase(self, source_code_content: str) -> str:
        """
        Phase 4: Testing Strategy & Test Cases
        
        Args:
            source_code_content (str): Content from coding phase
            
        Returns:
            str: Generated testing content
        """
        logger.info("üß™ Starting Phase 4: Testing Strategy & Test Cases")
        
        # Load and prepare prompt
        testing_prompt = self.load_prompt_template("testing")
        formatted_prompt = testing_prompt.replace("{source_code_content}", source_code_content)
        
        # Get Gemini 2.5 Pro response via OpenRouter
        testing_content = get_gemini_response(formatted_prompt)
        if not testing_content:
            raise HTTPException(status_code=500, detail="Failed to generate testing documentation")
        
        # Save output
        self.save_output("tests.md", testing_content)
        
        logger.info("‚úÖ Phase 4 completed: Testing Strategy & Test Cases")
        return testing_content

    async def execute_documentation_phase(self, analysis_content: str, design_content: str, 
                                        source_code_content: str, testing_content: str) -> str:
        """
        Phase 5: Final Documentation
        
        Args:
            analysis_content (str): Content from analysis phase
            design_content (str): Content from design phase
            source_code_content (str): Content from coding phase
            testing_content (str): Content from testing phase
            
        Returns:
            str: Generated documentation content
        """
        logger.info("üìö Starting Phase 5: Final Documentation")
        
        # Load and prepare prompt
        documentation_prompt = self.load_prompt_template("documentation")
        formatted_prompt = documentation_prompt.replace("{analysis_content}", analysis_content)
        formatted_prompt = formatted_prompt.replace("{design_content}", design_content)
        formatted_prompt = formatted_prompt.replace("{source_code_content}", source_code_content)
        formatted_prompt = formatted_prompt.replace("{testing_content}", testing_content)
        
        # Get Gemini 2.5 Pro response via OpenRouter
        documentation_content = get_gemini_response(formatted_prompt)
        if not documentation_content:
            raise HTTPException(status_code=500, detail="Failed to generate project documentation")
        
        # Save output
        self.save_output("documentation.md", documentation_content)
        
        logger.info("‚úÖ Phase 5 completed: Final Documentation")
        return documentation_content

    async def orchestrate_full_pipeline(self, project_description: str) -> Dict[str, Any]:
        """
        Execute the complete AI agent pipeline sequentially
        
        Args:
            project_description (str): User's project description
            
        Returns:
            Dict[str, Any]: Execution results and file paths
        """
        start_time = datetime.now()
        logger.info("üöÄ Starting complete AI agent pipeline execution")
        
        try:
            # Phase 1: Analysis
            analysis_content = await self.execute_analysis_phase(project_description)
            
            # Phase 2: Design
            design_content = await self.execute_design_phase(analysis_content)
            
            # Phase 3: Coding
            source_code_content = await self.execute_coding_phase(design_content)
            
            # Phase 4: Testing
            testing_content = await self.execute_testing_phase(source_code_content)
            
            # Phase 5: Documentation
            documentation_content = await self.execute_documentation_phase(
                analysis_content, design_content, source_code_content, testing_content
            )
            
            # Phase 6: Real Project Generation (NEW!)
            logger.info("üîß Starting Phase 6: Real Project Generation")
            implementation_md_path = os.path.join(self.source_code_dir, "implementation.md")
            project_generation_result = self.generate_real_project_from_docs(
                implementation_md_path, 
                self.source_code_dir
            )
            logger.info("‚úÖ Phase 6 completed: Real Project Generation")
            
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            logger.info(f"üéâ Pipeline completed successfully in {execution_time:.2f} seconds")
            logger.info(f"üìä Generated {project_generation_result.get('total_files', 0)} real project files")
            
            return {
                "success": True,
                "message": "AI agent pipeline completed successfully",
                "execution_time": execution_time,
                "outputs": {
                    "analysis": os.path.join(self.outputs_dir, "analysis.md"),
                    "design": os.path.join(self.outputs_dir, "design.md"),
                    "source_code": os.path.join(self.source_code_dir, "implementation.md"),
                    "testing": os.path.join(self.outputs_dir, "tests.md"),
                    "documentation": os.path.join(self.outputs_dir, "documentation.md")
                },
                "project_generation": {
                    "success": project_generation_result.get("success", False),
                    "message": project_generation_result.get("message", ""),
                    "created_files": project_generation_result.get("created_files", []),
                    "created_directories": project_generation_result.get("created_directories", []),
                    "total_files": project_generation_result.get("total_files", 0),
                    "total_directories": project_generation_result.get("total_directories", 0)
                }
            }
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"‚ùå Pipeline execution failed: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Pipeline execution failed: {str(e)}")

    def parse_implementation_markdown(self, markdown_content: str) -> List[Tuple[str, str, str]]:
        """
        Parse implementation.md to extract file paths, languages, and code content
        
        Args:
            markdown_content (str): Content of implementation.md file
            
        Returns:
            List[Tuple[str, str, str]]: List of (file_path, language, code_content) tuples
        """
        try:
            logger.info("üîç Parsing implementation markdown for file extraction")
            
            # Regex pattern to match markdown code blocks with file headers
            # Matches patterns like:
            # ## path/to/file.ext
            # ```language
            # code content
            # ```
            pattern = r'##\s+`?([^`\n]+?)`?\s*\n\s*```(\w+)?\s*\n(.*?)\n\s*```'
            
            matches = re.findall(pattern, markdown_content, re.DOTALL | re.MULTILINE)
            
            extracted_files = []
            
            for match in matches:
                file_path = match[0].strip()
                language = match[1].strip() if match[1] else 'text'
                code_content = match[2].strip()
                
                # Clean up file path (remove any extra formatting)
                file_path = file_path.replace('`', '').strip()
                
                # Skip empty files or invalid paths
                if not file_path or not code_content:
                    continue
                
                extracted_files.append((file_path, language, code_content))
                logger.info(f"üìÑ Found file: {file_path} ({language})")
            
            logger.info(f"‚úÖ Successfully parsed {len(extracted_files)} files from markdown")
            return extracted_files
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing implementation markdown: {str(e)}")
            return []

    def generate_real_project_from_docs(self, implementation_md_path: str, output_directory: str) -> Dict[str, Any]:
        """
        Generate real project files from implementation markdown documentation
        
        Args:
            implementation_md_path (str): Path to implementation.md file
            output_directory (str): Directory where project files should be created
            
        Returns:
            Dict[str, Any]: Result summary with created files and directories
        """
        try:
            logger.info("üöÄ Starting real project generation from documentation")
            logger.info(f"üìÇ Source: {implementation_md_path}")
            logger.info(f"üìÅ Target: {output_directory}")
            
            # Read implementation markdown file
            if not os.path.exists(implementation_md_path):
                raise FileNotFoundError(f"Implementation markdown not found: {implementation_md_path}")
            
            with open(implementation_md_path, 'r', encoding='utf-8') as file:
                markdown_content = file.read()
            
            # Parse markdown to extract files
            extracted_files = self.parse_implementation_markdown(markdown_content)
            
            if not extracted_files:
                logger.warning("‚ö†Ô∏è No files found in implementation markdown")
                return {
                    "success": False,
                    "message": "No files found in implementation markdown",
                    "created_files": [],
                    "created_directories": []
                }
            
            # Prepare output directory
            output_path = Path(output_directory)
            output_path.mkdir(parents=True, exist_ok=True)
            
            created_files = []
            created_directories = set()
            
            # Create files and directories
            for file_path, language, code_content in extracted_files:
                try:
                    # Create full file path
                    full_file_path = output_path / file_path
                    
                    # Create parent directories if they don't exist
                    parent_dir = full_file_path.parent
                    if not parent_dir.exists():
                        parent_dir.mkdir(parents=True, exist_ok=True)
                        created_directories.add(str(parent_dir.relative_to(output_path)))
                        logger.info(f"üìÅ Created directory: {parent_dir.relative_to(output_path)}")
                    
                    # Write file content
                    with open(full_file_path, 'w', encoding='utf-8') as file:
                        # Add header comment based on file type
                        if language in ['javascript', 'js']:
                            file.write(f"// Generated by AI Agent MVP - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                        elif language in ['python', 'py']:
                            file.write(f"# Generated by AI Agent MVP - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                        elif language in ['html']:
                            file.write(f"<!-- Generated by AI Agent MVP - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} -->\n\n")
                        elif language in ['css']:
                            file.write(f"/* Generated by AI Agent MVP - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} */\n\n")
                        
                        file.write(code_content)
                    
                    created_files.append(str(full_file_path.relative_to(output_path)))
                    logger.info(f"üìÑ Created file: {full_file_path.relative_to(output_path)}")
                    
                except Exception as file_error:
                    logger.error(f"‚ùå Error creating file {file_path}: {str(file_error)}")
                    continue
            
            # Generate summary
            result = {
                "success": True,
                "message": f"Successfully generated {len(created_files)} files in {len(created_directories)} directories",
                "created_files": sorted(created_files),
                "created_directories": sorted(list(created_directories)),
                "total_files": len(created_files),
                "total_directories": len(created_directories)
            }
            
            logger.info(f"üéâ Project generation completed successfully!")
            logger.info(f"üìä Created {len(created_files)} files in {len(created_directories)} directories")
            
            return result
            
        except FileNotFoundError as e:
            logger.error(f"‚ùå File not found: {str(e)}")
            raise HTTPException(status_code=404, detail=str(e))
        except Exception as e:
            logger.error(f"‚ùå Error generating real project: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Project generation failed: {str(e)}")

# Initialize orchestrator
orchestrator = AIAgentOrchestrator()

@app.get("/")
async def root():
    """Root endpoint - health check"""
    return {
        "message": "AI Agent MVP is running successfully",
        "version": "1.0.0",
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "AI Agent MVP"
    }

@app.post("/generate", response_model=ProjectResponse)
async def generate_project(request: ProjectRequest):
    """
    Main endpoint to generate a complete software project
    
    This endpoint orchestrates the entire AI agent pipeline:
    1. Analysis ‚Üí GPT-4o ‚Üí Save analysis.md
    2. Design ‚Üí GPT-4o ‚Üí Save design.md
    3. Coding ‚Üí GPT-4o ‚Üí Save source_code/implementation.md
    4. Testing ‚Üí GPT-4o ‚Üí Save tests.md
    5. Documentation ‚Üí GPT-4o ‚Üí Save documentation.md
    """
    logger.info(f"üìù Received project generation request: {request.description[:100]}...")
    
    if not request.description or len(request.description.strip()) < 10:
        raise HTTPException(
            status_code=400, 
            detail="Project description must be at least 10 characters long"
        )
    
    try:
        # Execute the complete pipeline
        result = await orchestrator.orchestrate_full_pipeline(request.description)
        
        return ProjectResponse(**result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Unexpected error in generate_project: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    logger.info("üöÄ Starting AI Agent MVP server...")
    uvicorn.run(app, host="0.0.0.0", port=8000) 